import os
import json
import pdfplumber
from typing import List, Optional, Literal
from pydantic import BaseModel, Field
from openai import OpenAI
import dotenv

# åŠ è½½ç¯å¢ƒå˜é‡ (ç¡®ä¿ä½ æœ‰ OPENAI_API_KEY)
dotenv.load_dotenv()

# ==========================================
# 1. å®šä¹‰æ•°æ®ç»“æ„ (Schema Definition)
# è¿™æ˜¯ Agent 1 å’Œ Agent 2 ä¹‹é—´çš„ "åè®®"
# ==========================================


class RuleCondition(BaseModel):
    """å®šä¹‰å•æ¡è§„åˆ™çš„é€»è¾‘"""

    category: Literal["height", "enclosure", "special_use"] = Field(
        ..., description="è§„åˆ™ç±»åˆ«"
    )
    description: str = Field(..., description="è§„åˆ™çš„ç®€çŸ­æ–‡å­—æè¿°ï¼Œå¦‚'å±‚é«˜å°äº2.2ç±³'")
    condition_logic: str = Field(
        ..., description="ç”¨äºåç»­ä»£ç åŒ¹é…çš„é€»è¾‘ä¼ªä»£ç ï¼Œå¦‚ 'h < 2.2'"
    )
    coefficient: float = Field(..., description="è®¡ç®—ç³»æ•°: 1.0, 0.5, or 0.0")
    citation: str = Field(..., description="å¼•ç”¨æ³•è§„åŸæ–‡æ¡æ¬¾ï¼Œç”¨äº UI å±•ç¤º")


class RegulationOutput(BaseModel):
    """Agent 1 çš„æœ€ç»ˆè¾“å‡ºç»“æ„"""

    region: str = Field(..., description="æ³•è§„é€‚ç”¨çš„åœ°åŒº/ç‰ˆæœ¬")
    height_requirements: List[RuleCondition] = Field(description="å…³äºå±‚é«˜çš„è§„åˆ™é›†åˆ")
    enclosure_requirements: List[RuleCondition] = Field(
        description="å…³äºå›´æŠ¤ç»“æ„/é˜³å°çš„è§„åˆ™é›†åˆ"
    )
    special_space_requirements: List[RuleCondition] = Field(
        description="å…³äºç‰¹æ®Šç”¨é€”ç©ºé—´çš„è§„åˆ™é›†åˆ"
    )

    # CoT: è®©æ¨¡å‹è¾“å‡ºå®ƒçš„æ€è€ƒè¿‡ç¨‹
    reasoning_trace: str = Field(
        description="æ¨¡å‹çš„æ€ç»´é“¾(CoT)æ‘˜è¦ï¼Œè§£é‡Šå®ƒæ˜¯å¦‚ä½•æå–è¿™äº›è§„åˆ™çš„"
    )


# ==========================================
# 2. Regulation Analysis Agent ç±»
# ==========================================


class RegulationAnalysisAgent:
    def __init__(self, model_name="gpt-4o"):
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model_name

    def _extract_text_from_pdf(self, pdf_path: str) -> str:
        """å·¥å…·å‡½æ•°ï¼šä» PDF æå–æ–‡æœ¬"""
        print(f"ğŸ“„ [Agent 1] Reading PDF: {pdf_path}...")
        text_content = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    text_content += page.extract_text() + "\n"
        except Exception as e:
            print(f"âŒ Error reading PDF: {e}")
            return ""

        # ç®€å•æˆªæ–­é˜²æ­¢è¶…å‡º token é™åˆ¶ (å®é™…ç”Ÿäº§ä¸­å¯ä»¥ä½¿ç”¨ RAG æŠ€æœ¯åˆ†å—æ£€ç´¢)
        # å¢åŠ é™åˆ¶åˆ° 200,000 å­—ç¬¦ï¼Œä»¥ç¡®ä¿è¦†ç›–å¤§å¤šæ•°å®Œæ•´æ³•è§„
        return text_content[:200000]

    def analyze(self, pdf_path: str, region_name: str) -> dict:
        """
        æ‰§è¡Œ ReAct æµç¨‹ï¼š
        1. è·å–è¾“å…¥ (PDF)
        2. æ„å»º Prompt (åŒ…å« CoT æŒ‡ä»¤)
        3. è°ƒç”¨ LLM
        4. ç»“æ„åŒ–è¾“å‡º
        """
        raw_text = self._extract_text_from_pdf(pdf_path)
        if not raw_text:
            return {"error": "No text extracted"}

        print(f"ğŸ§  [Agent 1] Analyzing regulations for {region_name} ...")

        # --- System Prompt: å®šä¹‰è§’è‰²ä¸æ€ç»´æ–¹å¼ ---
        system_prompt = """
        You are an expert Architect and Compliance Analyst Agent. 
        Your goal is to extract 'Area Calculation Rules' from building regulation texts.
        
        You must verify the rules against three specific categories:
        1. **Story Height Requirements**: Look for threshold values (e.g., 2.2m, 3.6m) that change the calculation coefficient (1.0 vs 0.5).
        2. **Covering/Enclosure**: Look for keywords like 'Balcony' (é˜³å°), 'Enclosed' (å°é—­), 'Unenclosed' (æœªå°é—­), 'Canopy' (é›¨æ£š). Determine if they calculate full (1.0) or half (0.5) area.
        3. **Special Use**: Look for 'Basement', 'Shared Area', 'Fire Refuge', 'Equipment Room', 'Parking', 'Auxiliary Room', 'Deformation Joint'.
        
        **CRITICAL INSTRUCTIONS:**
        - **BE EXHAUSTIVE**: Do not summarize or omit any rules. Extract EVERY single clause that mentions area calculation logic.
        - **DETAILS MATTER**: If a rule has multiple sub-conditions (e.g. "Bay window > 2.1m" AND "Bay window < 2.1m"), create SEPARATE entries for each.
        - **NO HALLUCINATION**: Only extract rules explicitly present in the text.
        - **KEYWORDS**: Pay special attention to: é˜³å° (Balcony), é£˜çª—/å‡¸çª— (Bay Window), åœ°ä¸‹å®¤ (Basement), é›¨ç¯· (Canopy), å˜å½¢ç¼ (Deformation Joint), ç»“æ„å±‚é«˜ (Story Height).
        
        **Chain of Thought Process:**
        1. First, scan the text for keywords related to 'Area Calculation' (å»ºç­‘é¢ç§¯è®¡ç®—).
        2. Quote the specific clause.
        3. Determine the logic: IF condition THEN coefficient.
        4. Finally, output the structured JSON.
        """

        # --- User Prompt: ä¼ å…¥æ•°æ® ---
        user_prompt = f"""
        Region/Standard Name: {region_name}
        
        Raw Regulation Text:
        {raw_text}
        
        Please output the result strictly matching the JSON Schema provided.
        """

        try:
            # ä½¿ç”¨ OpenAI çš„ Structured Outputs (JSON Mode) ç¡®ä¿æ ¼å¼ç¨³å®š
            response = self.client.beta.chat.completions.parse(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                response_format=RegulationOutput,
                temperature=0,  # Set to 0 to ensure deterministic output
            )

            result = response.choices[0].message.parsed

            print("âœ… [Agent 1] Analysis Complete.")
            return result.model_dump()

        except Exception as e:
            print(f"âŒ [Agent 1] LLM Error: {e}")
            return {}


# ==========================================
# 3. æ¨¡æ‹Ÿè¿è¡Œ (Mock Execution)
# ==========================================

if __name__ == "__main__":
    # å‡è®¾ä½ æœ‰ä¸€ä¸ªæµ‹è¯•ç”¨çš„ PDF (ä½ éœ€è¦çœŸçš„æ”¾ä¸€ä¸ª PDF åœ¨è¿™é‡Œæ‰èƒ½è¿è¡Œï¼Œæ¯”å¦‚ã€Šå»ºç­‘å·¥ç¨‹å»ºç­‘é¢ç§¯è®¡ç®—è§„èŒƒ GB/T 50353-2013ã€‹)
    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘å°†æ¨¡æ‹Ÿä¸€ä¸ª PDF çš„æ–‡æœ¬å†…å®¹ï¼Œç»•è¿‡æ–‡ä»¶è¯»å–ï¼Œç›´æ¥æµ‹è¯• LLM é€»è¾‘

    agent = RegulationAnalysisAgent()

    # æ¨¡æ‹Ÿ PDF æ–‡æœ¬ (å®é™…ä½¿ç”¨æ—¶è°ƒç”¨ agent.analyze(pdf_path="..."))
    mock_pdf_text = """
    ...
    3.0.1 åœ¨ä¸»ä½“ç»“æ„å†…çš„é˜³å°ï¼Œåº”æŒ‰å…¶ç»“æ„å¤–å›´æ°´å¹³é¢ç§¯è®¡ç®—å…¨é¢ç§¯ï¼›åœ¨ä¸»ä½“ç»“æ„å¤–çš„é˜³å°ï¼Œåº”æŒ‰å…¶ç»“æ„åº•æ¿æ°´å¹³æŠ•å½±é¢ç§¯è®¡ç®—1/2é¢ç§¯ã€‚
    3.0.2 å»ºç­‘ç‰©çš„å»ºç­‘é¢ç§¯åº”æŒ‰è‡ªç„¶å±‚å¤–å¢™ç»“æ„å¤–å›´æ°´å¹³é¢ç§¯ä¹‹å’Œè®¡ç®—ã€‚ç»“æ„å±‚é«˜åœ¨2.20måŠä»¥ä¸Šçš„ï¼Œåº”è®¡ç®—å…¨é¢ç§¯ï¼›ç»“æ„å±‚é«˜åœ¨2.20mä»¥ä¸‹çš„ï¼Œåº”è®¡ç®—1/2é¢ç§¯ã€‚
    3.0.24 å»ºç­‘ç‰©å†…çš„å˜å½¢ç¼ï¼Œåº”æŒ‰å…¶è‡ªç„¶å±‚åˆå¹¶åœ¨å»ºç­‘ç‰©é¢ç§¯å†…è®¡ç®—ã€‚
    ...
    """

    # ç”±äºæ²¡æœ‰çœŸå® PDFï¼Œè¿™é‡Œæˆ‘æ‰‹åŠ¨ patch ä¸€ä¸‹ _extract_text_from_pdf ç”¨äºæ¼”ç¤º
    agent._extract_text_from_pdf = lambda x: mock_pdf_text

    # è¿è¡Œåˆ†æ
    json_result = agent.analyze("fake_path.pdf", "National Standard 2013")

    # æ‰“å°ç»“æœ (Pretty Print)
    print(json.dumps(json_result, indent=2, ensure_ascii=False))
